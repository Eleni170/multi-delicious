{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149925\n",
      "['rubi rail helper demo more info auto complet', 'see new helper action', 'null length substr locat', 'exec messag messag pleas edit remov follow word content', 'roll stone com news song previou next page', 'good vibrat beach boy', 'smell teen spirit nirvana', 'want hold hand beatl', 'hound dog elvi', 'god know beach boy', 'walk line johnni cash', 'heaven led zeppelin']\n",
      "149925\n",
      "965852\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "path = \"../Data/\"\n",
    "words = []\n",
    "\n",
    "\n",
    "def train_to_sentence_form(path):\n",
    "    # reads the file to a format of docs[doc[[sentence1],[sentence2]],...]\n",
    "    docs=[]\n",
    "    num_of_sentences = []\n",
    "    with open(path) as f:\n",
    "        line = f.readline()\n",
    "        while line:\n",
    "            line = line.rstrip('\\n').split(\" \")\n",
    "            #print(line)\n",
    "            num = line.pop(0)\n",
    "            #print(num)\n",
    "            number = int(num[1:-1])\n",
    "            num_of_sentences.append(number)\n",
    "            len_of_sentence = []\n",
    "\n",
    "            for i,k in enumerate(line):\n",
    "                if k.startswith('<'):\n",
    "                    k=k[1:-1]\n",
    "                    len_of_sentence.append(int(k))\n",
    "                    line.pop(i)\n",
    "            doc_sentence=[]       \n",
    "            sentence=[]\n",
    "            for j in len_of_sentence:\n",
    "                sentence = line[:j]\n",
    "                line=line[j:]\n",
    "                docs.append( sentence) \n",
    "            line = f.readline()\n",
    "    print(len(docs))\n",
    "    return docs,num_of_sentences     \n",
    "    #docs is a list of lists where each list is a different sentence\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "vocabs = open(path+\"vocabs.txt\").readlines()\n",
    "for vocab in vocabs:\n",
    "    word, _ = vocab.split(', ')\n",
    "    words.append(word)\n",
    "\n",
    "train_label = [i.strip() for i in open(path+\"train-label.dat\").readlines()]\n",
    "train_label = np.array(train_label)\n",
    "\n",
    "#path=\"../Data/\"\n",
    "docs,num_sentences = train_to_sentence_form(path+\"train-data.dat\")\n",
    "\n",
    "#train_data = convert_to_word(path + \"/train-data.dat\")\n",
    "data = []\n",
    "for i in docs:\n",
    "    final_L = ''\n",
    "    for l in i:\n",
    "        final_L = final_L + ' ' + words[int(l)]\n",
    "    data.append(final_L[1:])\n",
    "print(data[:12])\n",
    "print(len(data))       \n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(data)\n",
    "print(X_train_counts.size)\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multilabel_confusion_matrix(predict,path,clustnum=0):\n",
    "    test_label = [i.strip().split() for i in open(path + \"test-label.dat\").readlines()]\n",
    "\n",
    "    for i in range(len(test_label)):\n",
    "        item = test_label[i]\n",
    "        for j in range(len(item)):\n",
    "            item[j] = int(item[j])\n",
    "\n",
    "        test_label[i] = item\n",
    "\n",
    "    labels = []\n",
    "\n",
    "    for item in open(path + \"labels.txt\").readlines():\n",
    "        item = item.replace('\\n', '')\n",
    "        label_name, _ = item.split(', ')\n",
    "        labels.append(label_name)\n",
    "\n",
    "    y_true = np.array(test_label)\n",
    "    y_pred = np.array(predict)\n",
    "\n",
    "    conf_mat_dict = {}\n",
    "\n",
    "    for label_col in range(len(labels)):\n",
    "        y_true_label = y_true[:, label_col]\n",
    "        y_pred_label = y_pred[:, label_col]\n",
    "        conf_mat_dict[labels[label_col]] = confusion_matrix(y_pred=y_pred_label, y_true=y_true_label)\n",
    "    f = open(\"confmatrix\"+str(clustnum)+\".txt\", \"w\")\n",
    "    f.close()\n",
    "    for label, matrix in conf_mat_dict.items():\n",
    "        print(\"Confusion matrix for label {}:\".format(label))\n",
    "        f = open(\"confmatrix\"+str(clustnum)+\".txt\", \"a\")\n",
    "        print(matrix)\n",
    "        f.write(\"Confusion matrix for label {}:\".format(label))\n",
    "        np.savetxt(f,matrix)\n",
    "        f.close()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: costcla in c:\\users\\peris\\anaconda3\\lib\\site-packages (0.6)\n",
      "Requirement already satisfied: pyea>=0.2 in c:\\users\\peris\\anaconda3\\lib\\site-packages (from costcla) (0.2)\n",
      "Requirement already satisfied: scikit-learn>=0.15.0b2 in c:\\users\\peris\\anaconda3\\lib\\site-packages (from costcla) (0.21.3)\n",
      "Requirement already satisfied: numpy>=1.8.0 in c:\\users\\peris\\anaconda3\\lib\\site-packages (from costcla) (1.16.5)\n",
      "Requirement already satisfied: pandas>=0.14.0 in c:\\users\\peris\\anaconda3\\lib\\site-packages (from costcla) (0.25.3)\n",
      "Requirement already satisfied: scipy>=0.17.0 in c:\\users\\peris\\anaconda3\\lib\\site-packages (from scikit-learn>=0.15.0b2->costcla) (1.4.1)\n",
      "Requirement already satisfied: joblib>=0.11 in c:\\users\\peris\\appdata\\roaming\\python\\python37\\site-packages (from scikit-learn>=0.15.0b2->costcla) (0.14.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in c:\\users\\peris\\anaconda3\\lib\\site-packages (from pandas>=0.14.0->costcla) (2019.3)\n",
      "Requirement already satisfied: python-dateutil>=2.6.1 in c:\\users\\peris\\anaconda3\\lib\\site-packages (from pandas>=0.14.0->costcla) (2.8.0)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\peris\\anaconda3\\lib\\site-packages (from python-dateutil>=2.6.1->pandas>=0.14.0->costcla) (1.12.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Peris\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\joblib\\__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n",
      "C:\\Users\\Peris\\Anaconda3\\lib\\site-packages\\sklearn\\externals\\six.py:31: DeprecationWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
      "  \"(https://pypi.org/project/six/).\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "#from pandas import costcla\n",
    "!pip install costcla\n",
    "from costcla.metrics import cost_loss\n",
    "from costcla.models import CostSensitiveLogisticRegression\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "def calculate_cost_matrix(y_list):\n",
    "    y_list_len = len(y_list)\n",
    "    #print(y_list_len)\n",
    "    percentage_0 = np.count_nonzero(y_list == 0) / y_list_len\n",
    "    percentage_1 = np.count_nonzero(y_list == 1) / y_list_len\n",
    "    #print(percentage_0)\n",
    "    #print(percentage_1)\n",
    "    #print(1 / (percentage_0 * y_list_len))\n",
    "    #print( 1 / (percentage_1 * y_list_len))\n",
    "    cost_matrix = []\n",
    "    for i in range(len(y_list)):\n",
    "        cost_matrix.append([1 / (percentage_0 * y_list_len), 1 / (percentage_1 * y_list_len),  0, 0])\n",
    "\n",
    "    return np.array(cost_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73363\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "test_data,test_sentences = train_to_sentence_form(path+\"test-data.dat\")\n",
    "test_label = [i.strip() for i in open(path+\"test-label.dat\").readlines()]\n",
    "test_label = np.array(test_label)\n",
    "train_label = [i.strip() for i in open(path+\"train-label.dat\").readlines()]\n",
    "train_label = np.array(train_label)\n",
    "\n",
    "df = pd.read_csv(\"../multi-instance/k_means/train_kmeans.csv\") \n",
    "df_test = pd.read_csv(\"../multi-instance/k_means/test_kmeans.csv\")\n",
    "#train_label = pd.DataFrame(data = train_label)\n",
    "labels_models=[]\n",
    "for i in range (0,20 ):\n",
    "    tr=[]\n",
    "    for j in range (0,len(train_label)):\n",
    "        tr.append(int(train_label[j][2*i]))\n",
    "    labels_models.append(tr)\n",
    "    \n",
    "train_labels = pd.DataFrame(labels_models)\n",
    "train_labels = train_labels.transpose()\n",
    "#print(train_labels[:][2])\n",
    "labels__models=[]\n",
    "for i in range (0,20 ):\n",
    "    ts=[]\n",
    "    for j in range (0,len(test_label)):\n",
    "        ts.append(int(test_label[j][2*i]))\n",
    "    labels__models.append(ts)\n",
    "    \n",
    "test_labels = pd.DataFrame(labels__models)\n",
    "test_labels = test_labels.transpose()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8251, 20)\n",
      "(8251, 21)\n",
      "(8251, 22)\n",
      "(8251, 23)\n",
      "(8251, 24)\n",
      "(8251, 25)\n",
      "(8251, 26)\n",
      "(8251, 27)\n",
      "(8251, 28)\n",
      "(8251, 29)\n",
      "(8251, 30)\n",
      "(8251, 31)\n",
      "(8251, 32)\n",
      "(8251, 33)\n",
      "(8251, 34)\n",
      "(8251, 35)\n",
      "(8251, 36)\n",
      "(8251, 37)\n",
      "(8251, 38)\n",
      "(8251, 39)\n",
      "      Label0  Label1  Label2  Label3  Label4  Label5  Label6  Label7  Label8  \\\n",
      "0        1.0     1.0     1.0     1.0     0.0     1.0     1.0     0.0     0.0   \n",
      "1        0.0     1.0     1.0     1.0     0.0     1.0     1.0     0.0     0.0   \n",
      "2        0.0     1.0     1.0     1.0     0.0     1.0     1.0     0.0     0.0   \n",
      "3        0.0     1.0     1.0     1.0     0.0     1.0     1.0     0.0     0.0   \n",
      "4        0.0     1.0     1.0     1.0     0.0     1.0     1.0     0.0     0.0   \n",
      "...      ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
      "3978     0.0     1.0     1.0     1.0     0.0     1.0     1.0     0.0     0.0   \n",
      "3979     0.0     1.0     1.0     1.0     0.0     1.0     1.0     0.0     0.0   \n",
      "3980     0.0     1.0     1.0     1.0     0.0     1.0     1.0     0.0     0.0   \n",
      "3981     0.0     1.0     1.0     1.0     0.0     1.0     1.0     0.0     0.0   \n",
      "3982     0.0     1.0     1.0     1.0     0.0     1.0     1.0     0.0     0.0   \n",
      "\n",
      "      Label9  Label10  Label11  Label12  Label13  Label14  Label15  Label16  \\\n",
      "0        1.0      1.0      0.0      0.0      1.0      0.0      0.0      0.0   \n",
      "1        1.0      0.0      0.0      0.0      1.0      1.0      0.0      0.0   \n",
      "2        1.0      0.0      0.0      0.0      1.0      0.0      0.0      0.0   \n",
      "3        1.0      1.0      0.0      0.0      1.0      0.0      0.0      0.0   \n",
      "4        1.0      1.0      0.0      0.0      1.0      0.0      0.0      1.0   \n",
      "...      ...      ...      ...      ...      ...      ...      ...      ...   \n",
      "3978     1.0      1.0      0.0      0.0      1.0      0.0      0.0      0.0   \n",
      "3979     1.0      0.0      0.0      0.0      1.0      0.0      0.0      0.0   \n",
      "3980     1.0      0.0      0.0      0.0      1.0      0.0      0.0      0.0   \n",
      "3981     1.0      1.0      0.0      0.0      1.0      0.0      0.0      1.0   \n",
      "3982     1.0      1.0      0.0      0.0      1.0      0.0      0.0      1.0   \n",
      "\n",
      "      Label17  Label18  Label19  \n",
      "0         0.0      0.0      0.0  \n",
      "1         0.0      0.0      0.0  \n",
      "2         0.0      0.0      0.0  \n",
      "3         0.0      0.0      0.0  \n",
      "4         0.0      0.0      0.0  \n",
      "...       ...      ...      ...  \n",
      "3978      0.0      0.0      0.0  \n",
      "3979      0.0      0.0      0.0  \n",
      "3980      0.0      0.0      0.0  \n",
      "3981      0.0      0.0      0.0  \n",
      "3982      0.0      0.0      0.0  \n",
      "\n",
      "[3983 rows x 20 columns]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#f = CostSensitiveLogisticRegression()\n",
    "#cost_mat_test = calculate_cost_matrix(test_labels)\n",
    "pred = pd.DataFrame()\n",
    "#print(df)\n",
    "#drop 1st column because of an error in 1st column\n",
    "\n",
    "#print(df)\n",
    "from sklearn import preprocessing\n",
    "x = df.values #returns a numpy array\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(x)\n",
    "df = pd.DataFrame(x_scaled)\n",
    "x = df_test.values #returns a numpy array\n",
    "x_scaled = min_max_scaler.transform(x)\n",
    "df_test = pd.DataFrame(x_scaled)\n",
    "\n",
    "orderlist = [2,7,4,0,8,6,5,12,10,9,17,11,15,14,3,13,16,1,18,19]\n",
    "for l in orderlist:\n",
    "    print(df.shape)\n",
    "    cost_mat_train = calculate_cost_matrix(train_labels[:][l])\n",
    "    f = CostSensitiveLogisticRegression()\n",
    "    f.fit(df, train_labels[:][l],cost_mat_train)\n",
    "    df['Label'+str(l)] = train_labels[:][l]\n",
    "    df_test['Label'+str(l)] = f.predict(df_test) \n",
    "    pred['Label'+str(l)] = df_test['Label'+str(l)]\n",
    "\n",
    "predorder = ['Label'+str(i) for i in range(20)]\n",
    "pred = pred[predorder]\n",
    "print(pred)\n",
    "#cost_loss(df_test, pred, cost_mat_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9330680161342277\n",
      "0.6952046196334422\n",
      "1.0000000000000002\n",
      "0.05724328395681647\n",
      "1.0\n",
      "0.3911624403715792\n",
      "1.0\n",
      "0.09339693698217424\n",
      "1.0\n",
      "0.7363796133567663\n",
      "0.9997098084735925\n",
      "0.13507406477529502\n",
      "0.9959383691477566\n",
      "0.18051719809189054\n",
      "1.0\n",
      "0.729098669344715\n",
      "1.0043136195242681\n",
      "0.7815716796384635\n",
      "1.0000000000000004\n",
      "0.12126537785588752\n",
      "0.9452339286808614\n",
      "0.28094401205121766\n",
      "1.0\n",
      "0.8799899573186041\n",
      "1.0026410053691017\n",
      "0.8684408737132815\n",
      "0.9594569622808518\n",
      "0.2093899071051971\n",
      "0.9734355730596331\n",
      "0.7165453175997991\n",
      "1.0\n",
      "0.8892794376098418\n",
      "1.1553130624002819\n",
      "0.7072558373085613\n",
      "1.0002871912693854\n",
      "0.8739643484810444\n",
      "0.9999999999999998\n",
      "0.9480291237760482\n",
      "1.0025974025974027\n",
      "0.9640974140095405\n",
      "Confusion matrix for label programming:\n",
      "[[2558  448]\n",
      " [ 766  211]]\n",
      "Confusion matrix for label style:\n",
      "[[   0 3755]\n",
      " [   0  228]]\n",
      "Confusion matrix for label reference:\n",
      "[[   0 2425]\n",
      " [   0 1558]]\n",
      "Confusion matrix for label java:\n",
      "[[   0 3611]\n",
      " [   0  372]]\n",
      "Confusion matrix for label web:\n",
      "[[2933    0]\n",
      " [1050    0]]\n",
      "Confusion matrix for label internet:\n",
      "[[   1 3445]\n",
      " [   0  537]]\n",
      "Confusion matrix for label culture:\n",
      "[[  18 3263]\n",
      " [   1  701]]\n",
      "Confusion matrix for label design:\n",
      "[[2904    0]\n",
      " [1079    0]]\n",
      "Confusion matrix for label education:\n",
      "[[3095   85]\n",
      " [ 785   18]]\n",
      "Confusion matrix for label language:\n",
      "[[   0 3500]\n",
      " [   0  483]]\n",
      "Confusion matrix for label books:\n",
      "[[ 684 2792]\n",
      " [  72  435]]\n",
      "Confusion matrix for label writing:\n",
      "[[3505    0]\n",
      " [ 478    0]]\n",
      "Confusion matrix for label computer:\n",
      "[[3458   16]\n",
      " [ 508    1]]\n",
      "Confusion matrix for label english:\n",
      "[[ 515 3113]\n",
      " [  36  319]]\n",
      "Confusion matrix for label politics:\n",
      "[[2752  839]\n",
      " [ 290  102]]\n",
      "Confusion matrix for label history:\n",
      "[[3542    0]\n",
      " [ 441    0]]\n",
      "Confusion matrix for label philosophy:\n",
      "[[2792  922]\n",
      " [ 244   25]]\n",
      "Confusion matrix for label science:\n",
      "[[3481    1]\n",
      " [ 501    0]]\n",
      "Confusion matrix for label religion:\n",
      "[[3776    0]\n",
      " [ 207    0]]\n",
      "Confusion matrix for label grammar:\n",
      "[[3840   10]\n",
      " [ 133    0]]\n"
     ]
    }
   ],
   "source": [
    "#print(df_test)\n",
    "#print(pred)\n",
    "#print(cost_mat_test.shape)\n",
    "from sklearn.metrics import accuracy_score\n",
    "for i in range(20):\n",
    "    cost_mat_test = calculate_cost_matrix(test_labels[:][i])\n",
    "    print(cost_loss(test_labels.iloc[:,i], pred.iloc[:,i], cost_mat_test))\n",
    "    print(accuracy_score(test_labels.iloc[:,i], pred.iloc[:,i]))\n",
    "'''predict=[]\n",
    "for p in range(3983):\n",
    "    #print(p)\n",
    "    result = []\n",
    "    for r in range(20):\n",
    "        x = orderlist.index(r)\n",
    "        result.append(pred.iloc[p,x])\n",
    "    predict.append(result)'''\n",
    "multilabel_confusion_matrix(pred,path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
