{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149925\n",
      "['rubi rail helper demo more info auto complet', 'see new helper action', 'null length substr locat', 'exec messag messag pleas edit remov follow word content', 'roll stone com news song previou next page', 'good vibrat beach boy', 'smell teen spirit nirvana', 'want hold hand beatl', 'hound dog elvi', 'god know beach boy', 'walk line johnni cash', 'heaven led zeppelin']\n",
      "149925\n",
      "965852\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "path = \"../Data/\"\n",
    "words = []\n",
    "\n",
    "\n",
    "def train_to_sentence_form(path):\n",
    "    # reads the file to a format of docs[doc[[sentence1],[sentence2]],...]\n",
    "    docs=[]\n",
    "    num_of_sentences = []\n",
    "    with open(path) as f:\n",
    "        line = f.readline()\n",
    "        while line:\n",
    "            line = line.rstrip('\\n').split(\" \")\n",
    "            #print(line)\n",
    "            num = line.pop(0)\n",
    "            #print(num)\n",
    "            number = int(num[1:-1])\n",
    "            num_of_sentences.append(number)\n",
    "            len_of_sentence = []\n",
    "\n",
    "            for i,k in enumerate(line):\n",
    "                if k.startswith('<'):\n",
    "                    k=k[1:-1]\n",
    "                    len_of_sentence.append(int(k))\n",
    "                    line.pop(i)\n",
    "            doc_sentence=[]       \n",
    "            sentence=[]\n",
    "            for j in len_of_sentence:\n",
    "                sentence = line[:j]\n",
    "                line=line[j:]\n",
    "                docs.append( sentence) \n",
    "            line = f.readline()\n",
    "    print(len(docs))\n",
    "    return docs,num_of_sentences     \n",
    "    #docs is a list of lists where each list is a different sentence\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "vocabs = open(path+\"vocabs.txt\").readlines()\n",
    "for vocab in vocabs:\n",
    "    word, _ = vocab.split(', ')\n",
    "    words.append(word)\n",
    "\n",
    "train_label = [i.strip() for i in open(path+\"train-label.dat\").readlines()]\n",
    "train_label = np.array(train_label)\n",
    "\n",
    "#path=\"../Data/\"\n",
    "docs,num_sentences = train_to_sentence_form(path+\"train-data.dat\")\n",
    "\n",
    "#train_data = convert_to_word(path + \"/train-data.dat\")\n",
    "data = []\n",
    "for i in docs:\n",
    "    final_L = ''\n",
    "    for l in i:\n",
    "        final_L = final_L + ' ' + words[int(l)]\n",
    "    data.append(final_L[1:])\n",
    "print(data[:12])\n",
    "print(len(data))       \n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(data)\n",
    "print(X_train_counts.size)\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multilabel_confusion_matrix(predict,path,clustnum=-3):\n",
    "    test_label = [i.strip().split() for i in open(path + \"test-label.dat\").readlines()]\n",
    "\n",
    "    for i in range(len(test_label)):\n",
    "        item = test_label[i]\n",
    "        for j in range(len(item)):\n",
    "            item[j] = int(item[j])\n",
    "\n",
    "        test_label[i] = item\n",
    "\n",
    "    labels = []\n",
    "\n",
    "    for item in open(path + \"labels.txt\").readlines():\n",
    "        item = item.replace('\\n', '')\n",
    "        label_name, _ = item.split(', ')\n",
    "        labels.append(label_name)\n",
    "\n",
    "    y_true = np.array(test_label)\n",
    "    y_pred = np.array(predict)\n",
    "\n",
    "    conf_mat_dict = {}\n",
    "\n",
    "    for label_col in range(len(labels)):\n",
    "        y_true_label = y_true[:, label_col]\n",
    "        y_pred_label = y_pred[:, label_col]\n",
    "        conf_mat_dict[labels[label_col]] = confusion_matrix(y_pred=y_pred_label, y_true=y_true_label)\n",
    "    f = open(\"confmatrix\"+str(clustnum)+\".txt\", \"w\")\n",
    "    f.close()\n",
    "    for label, matrix in conf_mat_dict.items():\n",
    "        print(\"Confusion matrix for label {}:\".format(label))\n",
    "        f = open(\"confmatrix\"+str(clustnum)+\".txt\", \"a\")\n",
    "        print(matrix)\n",
    "        f.write(\"Confusion matrix for label {}:\".format(label))\n",
    "        np.savetxt(f,matrix)\n",
    "        f.close()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73363\n",
      "             0     1         2    3      4         5         6         7  \\\n",
      "0     0.000000  0.00  0.000000  0.0  0.000  0.000000  0.076923  0.000000   \n",
      "1     0.038462  0.00  0.133333  0.0  0.000  0.741935  0.076923  0.000000   \n",
      "2     0.000000  0.12  0.333333  0.0  0.000  0.387097  0.000000  0.000000   \n",
      "3     0.000000  0.00  0.000000  0.0  0.000  0.064516  0.000000  0.000000   \n",
      "4     0.000000  0.08  0.000000  0.0  0.125  0.032258  0.000000  0.000000   \n",
      "...        ...   ...       ...  ...    ...       ...       ...       ...   \n",
      "8246  0.000000  0.00  0.000000  0.0  0.000  0.225806  0.000000  0.181818   \n",
      "8247  0.000000  0.00  0.266667  0.0  0.000  0.645161  0.000000  0.000000   \n",
      "8248  0.000000  0.00  0.000000  0.0  0.000  0.677419  0.230769  0.272727   \n",
      "8249  0.000000  0.00  0.000000  0.0  0.000  0.096774  0.000000  0.000000   \n",
      "8250  0.000000  0.00  0.000000  0.0  0.000  0.032258  0.076923  0.000000   \n",
      "\n",
      "         8    9        10        11   12   13   14        15   16   17  \\\n",
      "0     0.05  0.0  0.000000  0.000000  0.0  0.0  0.0  0.000000  0.0  0.0   \n",
      "1     0.00  0.0  0.000000  0.000000  0.0  0.0  0.0  0.000000  0.0  0.0   \n",
      "2     0.05  0.0  0.000000  0.000000  0.0  0.3  0.0  0.000000  0.0  0.4   \n",
      "3     0.00  0.0  0.000000  0.000000  0.0  0.0  0.0  0.000000  0.0  0.0   \n",
      "4     0.10  0.0  0.000000  0.000000  0.0  0.0  0.0  0.000000  0.0  0.0   \n",
      "...    ...  ...       ...       ...  ...  ...  ...       ...  ...  ...   \n",
      "8246  0.00  0.0  0.000000  0.000000  0.0  0.0  0.0  0.000000  0.0  0.0   \n",
      "8247  0.00  0.0  0.111111  0.000000  0.0  0.0  0.0  0.000000  0.0  0.0   \n",
      "8248  0.00  0.0  0.000000  0.000000  0.0  0.0  0.0  0.250000  0.0  0.0   \n",
      "8249  0.00  0.0  0.000000  0.043478  0.0  0.0  0.0  0.083333  0.0  0.0   \n",
      "8250  0.00  0.0  0.111111  0.000000  0.0  0.0  0.0  0.000000  0.0  0.0   \n",
      "\n",
      "            18     19  \n",
      "0     0.000000  0.000  \n",
      "1     0.071429  0.000  \n",
      "2     0.000000  0.125  \n",
      "3     0.000000  0.000  \n",
      "4     0.000000  0.000  \n",
      "...        ...    ...  \n",
      "8246  0.000000  0.000  \n",
      "8247  0.000000  0.250  \n",
      "8248  0.000000  0.000  \n",
      "8249  0.000000  0.000  \n",
      "8250  0.000000  0.000  \n",
      "\n",
      "[8251 rows x 20 columns]\n",
      "             0     1         2         3       4         5         6  \\\n",
      "0     0.000000  0.00  0.400000  0.000000  0.0000  0.258065  0.000000   \n",
      "1     0.000000  0.08  0.266667  0.000000  0.0000  0.451613  0.000000   \n",
      "2     0.076923  0.08  0.600000  0.000000  0.0000  0.419355  0.000000   \n",
      "3     0.000000  0.20  0.000000  0.000000  0.1250  0.129032  0.153846   \n",
      "4     0.000000  0.00  0.000000  0.111111  0.0000  0.032258  0.000000   \n",
      "...        ...   ...       ...       ...     ...       ...       ...   \n",
      "3978  0.000000  0.00  0.066667  0.000000  0.0625  0.096774  0.000000   \n",
      "3979  0.000000  0.08  0.266667  0.000000  0.0000  0.516129  0.000000   \n",
      "3980  0.000000  0.00  0.000000  0.000000  0.1875  0.258065  0.230769   \n",
      "3981  0.000000  0.00  0.000000  0.111111  0.0000  0.032258  0.000000   \n",
      "3982  0.000000  0.00  0.000000  0.000000  0.0000  0.000000  0.000000   \n",
      "\n",
      "             7     8    9        10        11        12   13        14  \\\n",
      "0     0.090909  0.05  0.0  0.111111  0.043478  0.000000  0.3  0.000000   \n",
      "1     0.181818  0.10  0.0  0.333333  0.000000  0.032258  0.2  0.000000   \n",
      "2     0.000000  0.05  0.0  0.222222  0.000000  0.000000  0.1  0.000000   \n",
      "3     0.000000  0.00  0.0  0.111111  0.000000  0.000000  0.0  0.000000   \n",
      "4     0.000000  0.00  0.0  0.000000  0.000000  0.000000  0.0  0.000000   \n",
      "...        ...   ...  ...       ...       ...       ...  ...       ...   \n",
      "3978  0.000000  0.10  0.0  0.000000  0.000000  0.000000  0.0  0.000000   \n",
      "3979  0.000000  0.05  0.0  0.000000  0.086957  0.000000  0.0  0.000000   \n",
      "3980  0.000000  0.15  0.0  0.000000  0.000000  0.161290  0.1  0.000000   \n",
      "3981  0.000000  0.00  0.0  0.000000  0.000000  0.000000  0.0  0.000000   \n",
      "3982  0.000000  0.00  0.0  0.000000  0.000000  0.000000  0.0  0.333333   \n",
      "\n",
      "            15        16        17        18     19  \n",
      "0     0.000000  0.153846  0.466667  0.000000  0.125  \n",
      "1     0.083333  0.000000  0.000000  0.000000  0.000  \n",
      "2     0.000000  0.000000  0.066667  0.000000  0.000  \n",
      "3     0.083333  0.000000  0.066667  0.000000  0.375  \n",
      "4     0.000000  0.000000  0.133333  0.000000  0.000  \n",
      "...        ...       ...       ...       ...    ...  \n",
      "3978  0.000000  0.000000  0.000000  0.000000  0.000  \n",
      "3979  0.000000  0.000000  0.333333  0.000000  0.125  \n",
      "3980  0.250000  0.076923  0.133333  0.000000  0.250  \n",
      "3981  0.000000  0.000000  0.000000  0.071429  0.000  \n",
      "3982  0.000000  0.000000  0.066667  0.071429  0.000  \n",
      "\n",
      "[3983 rows x 20 columns]\n",
      "3181\n",
      "(6362, 20)\n",
      "2221\n",
      "(4442, 21)\n",
      "2203\n",
      "(4406, 22)\n",
      "2050\n",
      "(4100, 23)\n",
      "1559\n",
      "(6692, 24)\n",
      "1471\n",
      "(6780, 25)\n",
      "1211\n",
      "(7040, 26)\n",
      "1049\n",
      "(7202, 27)\n",
      "1034\n",
      "(7216, 28)\n",
      "1004\n",
      "(7246, 29)\n",
      "1001\n",
      "(7250, 30)\n",
      "939\n",
      "kkk\n",
      "(3656, 31)\n",
      "898\n",
      "kkk\n",
      "(3676, 32)\n",
      "830\n",
      "kkk\n",
      "(3710, 33)\n",
      "799\n",
      "kkk\n",
      "(3726, 34)\n",
      "725\n",
      "kkk\n",
      "(3762, 35)\n",
      "598\n",
      "kkk\n",
      "(3826, 36)\n",
      "479\n",
      "kkk\n",
      "(3886, 37)\n",
      "411\n",
      "kkk\n",
      "(3920, 38)\n",
      "224\n",
      "kkk\n",
      "(4012, 39)\n",
      "Confusion matrix for label programming:\n",
      "[[1754 1252]\n",
      " [ 382  595]]\n",
      "Confusion matrix for label style:\n",
      "[[3440  315]\n",
      " [ 201   27]]\n",
      "Confusion matrix for label reference:\n",
      "[[1423 1002]\n",
      " [ 819  739]]\n",
      "Confusion matrix for label java:\n",
      "[[2694  917]\n",
      " [ 231  141]]\n",
      "Confusion matrix for label web:\n",
      "[[1801 1132]\n",
      " [ 484  566]]\n",
      "Confusion matrix for label internet:\n",
      "[[2469  977]\n",
      " [ 357  180]]\n",
      "Confusion matrix for label culture:\n",
      "[[2368  913]\n",
      " [ 431  271]]\n",
      "Confusion matrix for label design:\n",
      "[[1673 1231]\n",
      " [ 561  518]]\n",
      "Confusion matrix for label education:\n",
      "[[2374  806]\n",
      " [ 565  238]]\n",
      "Confusion matrix for label language:\n",
      "[[2681  819]\n",
      " [ 348  135]]\n",
      "Confusion matrix for label books:\n",
      "[[2538  938]\n",
      " [ 343  164]]\n",
      "Confusion matrix for label writing:\n",
      "[[2616  889]\n",
      " [ 327  151]]\n",
      "Confusion matrix for label computer:\n",
      "[[2543  931]\n",
      " [ 364  145]]\n",
      "Confusion matrix for label english:\n",
      "[[2929  699]\n",
      " [ 290   65]]\n",
      "Confusion matrix for label politics:\n",
      "[[2830  761]\n",
      " [ 266  126]]\n",
      "Confusion matrix for label history:\n",
      "[[2559  983]\n",
      " [ 285  156]]\n",
      "Confusion matrix for label philosophy:\n",
      "[[2965  749]\n",
      " [ 178   91]]\n",
      "Confusion matrix for label science:\n",
      "[[2696  786]\n",
      " [ 368  133]]\n",
      "Confusion matrix for label religion:\n",
      "[[3277  499]\n",
      " [ 161   46]]\n",
      "Confusion matrix for label grammar:\n",
      "[[3448  402]\n",
      " [ 121   12]]\n"
     ]
    }
   ],
   "source": [
    "from imblearn import under_sampling, over_sampling\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "import pandas as pd\n",
    "# KMeans clustering a kind of clustering.\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "\n",
    "test_data,test_sentences = train_to_sentence_form(path+\"test-data.dat\")\n",
    "test_label = [i.strip() for i in open(path+\"test-label.dat\").readlines()]\n",
    "test_label = np.array(test_label)\n",
    "train_label = [i.strip() for i in open(path+\"train-label.dat\").readlines()]\n",
    "train_label = np.array(train_label)\n",
    "\n",
    "df = pd.read_csv(\"../multi-instance/k_means/train_kmeans_svd.csv\") \n",
    "df_test = pd.read_csv(\"../multi-instance/k_means/test_kmeans_svd.csv\")\n",
    "#train_label = pd.DataFrame(data = train_label)\n",
    "labels_models=[]\n",
    "for i in range (0,20 ):\n",
    "    tr=[]\n",
    "    for j in range (0,len(train_label)):\n",
    "        tr.append(int(train_label[j][2*i]))\n",
    "    labels_models.append(tr)\n",
    "    \n",
    "train_labels = pd.DataFrame(labels_models)\n",
    "train_labels = train_labels.transpose()\n",
    "#print(train_labels[:][2])\n",
    "labels__models=[]\n",
    "for i in range (0,20 ):\n",
    "    ts=[]\n",
    "    for j in range (0,len(test_label)):\n",
    "        ts.append(int(test_label[j][2*i]))\n",
    "    labels__models.append(ts)\n",
    "    \n",
    "test_labels = pd.DataFrame(labels__models)\n",
    "test_labels = test_labels.transpose()\n",
    "\n",
    "#print(df)\n",
    "#print(df_test)\n",
    "#df=df.drop(df.columns[0],axis=1)\n",
    "#df_test=df_test.drop(df_test.columns[0],axis=1)\n",
    "\n",
    "from sklearn import preprocessing\n",
    "x = df.values #returns a numpy array\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "x_scaled = min_max_scaler.fit_transform(x)\n",
    "df = pd.DataFrame(x_scaled)\n",
    "x = df_test.values #returns a numpy array\n",
    "x_scaled = min_max_scaler.transform(x)\n",
    "df_test = pd.DataFrame(x_scaled)\n",
    "\n",
    "print(df)\n",
    "print(df_test)\n",
    "\n",
    "from sklearn import neighbors\n",
    "pred = pd.DataFrame()\n",
    "sm = SMOTE(sampling_strategy=0.5, random_state=2)\n",
    "smsmall = SMOTE(sampling_strategy=0.25, random_state=2)\n",
    "rm = RandomUnderSampler(random_state=42)\n",
    "dfinit = df.copy()\n",
    "orderlist = [2,7,4,0,8,6,5,12,10,9,17,11,15,14,3,13,16,1,18,19]\n",
    "for l in orderlist:\n",
    "    print(train_labels[train_labels[:][l] == 1][l].size)\n",
    "    if train_labels[train_labels[:][l] == 1][l].size < 1000:\n",
    "        print(\"kkk\")\n",
    "        df, train_labels_new = smsmall.fit_resample(dfinit,train_labels[:][l])\n",
    "        df, train_labels_new = rm.fit_resample(df,train_labels_new)\n",
    "    elif train_labels[train_labels[:][l] == 1][l].size < 2000:\n",
    "        df, train_labels_new = sm.fit_resample(dfinit,train_labels[:][l])\n",
    "        df, train_labels_new = rm.fit_resample(df,train_labels_new)\n",
    "    else:\n",
    "        df, train_labels_new = rm.fit_resample(dfinit, train_labels[:][l])\n",
    "    print(df.shape)\n",
    "    KNN = neighbors.KNeighborsClassifier(n_neighbors=3 ,weights='distance',metric='minkowski',p=1).fit(df, train_labels_new)\n",
    "    dfinit['Label'+str(l)] = train_labels[:][l]\n",
    "    df_test['Label'+str(l)] = KNN.predict(df_test) \n",
    "    pred['Label'+str(l)] = df_test['Label'+str(l)]\n",
    "    \n",
    "\n",
    "#clustnum = -1 smote\n",
    "#-2 randomundersampler\n",
    "'''sm = SMOTE(sampling_strategy='not majority', random_state=2)\n",
    "df, train_labels = sm.fit_resample(df, train_labels)\n",
    "\n",
    "\n",
    "KNN = neighbors.KNeighborsClassifier(n_neighbors=3 ,weights='distance',metric='minkowski',p=1).fit(df, train_labels)'''\n",
    "\n",
    "\n",
    "#pred = KNN.predict(df_test)\n",
    "#print(pred)\n",
    "predict=[]\n",
    "for p in range(3983):\n",
    "    #print(p)\n",
    "    result = []\n",
    "    for r in range(20):\n",
    "        x = orderlist.index(r)\n",
    "        result.append(pred.iloc[p,x])\n",
    "    predict.append(result)\n",
    "    \n",
    "multilabel_confusion_matrix(predict,path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
