{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149925\n",
      "['rubi rail helper demo more info auto complet', 'see new helper action', 'null length substr locat', 'exec messag messag pleas edit remov follow word content', 'roll stone com news song previou next page', 'good vibrat beach boy', 'smell teen spirit nirvana', 'want hold hand beatl', 'hound dog elvi', 'god know beach boy', 'walk line johnni cash', 'heaven led zeppelin']\n",
      "149925\n",
      "965852\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "path = \"../Data/\"\n",
    "words = []\n",
    "\n",
    "\n",
    "def train_to_sentence_form(path):\n",
    "    # reads the file to a format of docs[doc[[sentence1],[sentence2]],...]\n",
    "    docs=[]\n",
    "    num_of_sentences = []\n",
    "    with open(path) as f:\n",
    "        line = f.readline()\n",
    "        while line:\n",
    "            line = line.rstrip('\\n').split(\" \")\n",
    "            #print(line)\n",
    "            num = line.pop(0)\n",
    "            #print(num)\n",
    "            number = int(num[1:-1])\n",
    "            num_of_sentences.append(number)\n",
    "            len_of_sentence = []\n",
    "\n",
    "            for i,k in enumerate(line):\n",
    "                if k.startswith('<'):\n",
    "                    k=k[1:-1]\n",
    "                    len_of_sentence.append(int(k))\n",
    "                    line.pop(i)\n",
    "            doc_sentence=[]       \n",
    "            sentence=[]\n",
    "            for j in len_of_sentence:\n",
    "                sentence = line[:j]\n",
    "                line=line[j:]\n",
    "                docs.append( sentence) \n",
    "            line = f.readline()\n",
    "    print(len(docs))\n",
    "    return docs,num_of_sentences     \n",
    "    #docs is a list of lists where each list is a different sentence\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "vocabs = open(path+\"vocabs.txt\").readlines()\n",
    "for vocab in vocabs:\n",
    "    word, _ = vocab.split(', ')\n",
    "    words.append(word)\n",
    "\n",
    "train_label = [i.strip() for i in open(path+\"train-label.dat\").readlines()]\n",
    "train_label = np.array(train_label)\n",
    "\n",
    "#path=\"../Data/\"\n",
    "docs,num_sentences = train_to_sentence_form(path+\"train-data.dat\")\n",
    "\n",
    "#train_data = convert_to_word(path + \"/train-data.dat\")\n",
    "data = []\n",
    "for i in docs:\n",
    "    final_L = ''\n",
    "    for l in i:\n",
    "        final_L = final_L + ' ' + words[int(l)]\n",
    "    data.append(final_L[1:])\n",
    "print(data[:12])\n",
    "print(len(data))       \n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(data)\n",
    "print(X_train_counts.size)\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multilabel_confusion_matrix(predict,path,clustnum=-3):\n",
    "    test_label = [i.strip().split() for i in open(path + \"test-label.dat\").readlines()]\n",
    "\n",
    "    for i in range(len(test_label)):\n",
    "        item = test_label[i]\n",
    "        for j in range(len(item)):\n",
    "            item[j] = int(item[j])\n",
    "\n",
    "        test_label[i] = item\n",
    "\n",
    "    labels = []\n",
    "\n",
    "    for item in open(path + \"labels.txt\").readlines():\n",
    "        item = item.replace('\\n', '')\n",
    "        label_name, _ = item.split(', ')\n",
    "        labels.append(label_name)\n",
    "\n",
    "    y_true = np.array(test_label)\n",
    "    y_pred = np.array(predict)\n",
    "\n",
    "    conf_mat_dict = {}\n",
    "\n",
    "    for label_col in range(len(labels)):\n",
    "        y_true_label = y_true[:, label_col]\n",
    "        y_pred_label = y_pred[:, label_col]\n",
    "        conf_mat_dict[labels[label_col]] = confusion_matrix(y_pred=y_pred_label, y_true=y_true_label)\n",
    "    f = open(\"confmatrix\"+str(clustnum)+\".txt\", \"w\")\n",
    "    f.close()\n",
    "    for label, matrix in conf_mat_dict.items():\n",
    "        print(\"Confusion matrix for label {}:\".format(label))\n",
    "        f = open(\"confmatrix\"+str(clustnum)+\".txt\", \"a\")\n",
    "        print(matrix)\n",
    "        f.write(\"Confusion matrix for label {}:\".format(label))\n",
    "        np.savetxt(f,matrix)\n",
    "        f.close()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73363\n",
      "      Cluster 0  Cluster 1  Cluster 2  Cluster 3  Cluster 4  Cluster 5  \\\n",
      "0           0.0        0.0        0.0        1.0        0.0        0.0   \n",
      "1           0.0        2.0       24.0        0.0        0.0        0.0   \n",
      "2           0.0        1.0       17.0        1.0        0.0        0.0   \n",
      "3           0.0        0.0        1.0        0.0        0.0        0.0   \n",
      "4           0.0        0.0        1.0        2.0        0.0        0.0   \n",
      "...         ...        ...        ...        ...        ...        ...   \n",
      "8246        0.0        0.0        4.0        0.0        0.0        0.0   \n",
      "8247        0.0        2.0       23.0        0.0        0.0        1.0   \n",
      "8248        0.0        0.0       15.0        0.0        0.0        0.0   \n",
      "8249        1.0        0.0        4.0        0.0        0.0        0.0   \n",
      "8250        0.0        0.0        1.0        0.0        0.0        1.0   \n",
      "\n",
      "      Cluster 6  Cluster 7  Cluster 8  Cluster 9  Cluster 10  Cluster 11  \\\n",
      "0           0.0        0.0        0.0        0.0         0.0         0.0   \n",
      "1           0.0        0.0        1.0        0.0         0.0         0.0   \n",
      "2           1.0        0.0        0.0        0.0         0.0         0.0   \n",
      "3           0.0        0.0        0.0        0.0         0.0         0.0   \n",
      "4           2.0        0.0        0.0        0.0         0.0         0.0   \n",
      "...         ...        ...        ...        ...         ...         ...   \n",
      "8246        1.0        2.0        0.0        0.0         0.0         1.0   \n",
      "8247        0.0        0.0        0.0        0.0         0.0         0.0   \n",
      "8248        0.0        3.0        0.0        1.0         0.0         0.0   \n",
      "8249        0.0        0.0        0.0        0.0         0.0         0.0   \n",
      "8250        0.0        0.0        0.0        0.0         0.0         0.0   \n",
      "\n",
      "      Cluster 12  Cluster 13  Cluster 14  Cluster 15  Cluster 16  Cluster 17  \\\n",
      "0            0.0         0.0         1.0         0.0         0.0         0.0   \n",
      "1            0.0         0.0         1.0         0.0         0.0         0.0   \n",
      "2            0.0         3.0         0.0         1.0         6.0         0.0   \n",
      "3            0.0         0.0         0.0         0.0         0.0         0.0   \n",
      "4            2.0         0.0         0.0         0.0         0.0         0.0   \n",
      "...          ...         ...         ...         ...         ...         ...   \n",
      "8246         0.0         0.0         0.0         0.0         0.0         1.0   \n",
      "8247         0.0         0.0         0.0         0.0         0.0         0.0   \n",
      "8248         0.0         0.0         2.0         0.0         0.0         9.0   \n",
      "8249         0.0         0.0         0.0         0.0         0.0         0.0   \n",
      "8250         0.0         0.0         1.0         0.0         0.0         0.0   \n",
      "\n",
      "      Cluster 18  Cluster 19  \n",
      "0            0.0         0.0  \n",
      "1            0.0         0.0  \n",
      "2            1.0         0.0  \n",
      "3            1.0         0.0  \n",
      "4            0.0         0.0  \n",
      "...          ...         ...  \n",
      "8246         0.0         0.0  \n",
      "8247         0.0         1.0  \n",
      "8248         0.0         0.0  \n",
      "8249         0.0         0.0  \n",
      "8250         0.0         0.0  \n",
      "\n",
      "[8251 rows x 20 columns]\n",
      "(6362, 20)\n",
      "(4442, 21)\n",
      "(4406, 22)\n",
      "(4100, 23)\n",
      "(3118, 24)\n",
      "(2942, 25)\n",
      "(2422, 26)\n",
      "(2098, 27)\n",
      "(2068, 28)\n",
      "(2008, 29)\n",
      "(2002, 30)\n",
      "(1878, 31)\n",
      "(1796, 32)\n",
      "(1660, 33)\n",
      "(1598, 34)\n",
      "(1450, 35)\n",
      "(1196, 36)\n",
      "(958, 37)\n",
      "(822, 38)\n",
      "(448, 39)\n",
      "Confusion matrix for label programming:\n",
      "[[1786 1220]\n",
      " [ 486  491]]\n",
      "Confusion matrix for label style:\n",
      "[[2570 1185]\n",
      " [ 151   77]]\n",
      "Confusion matrix for label reference:\n",
      "[[1389 1036]\n",
      " [ 844  714]]\n",
      "Confusion matrix for label java:\n",
      "[[2206 1405]\n",
      " [ 190  182]]\n",
      "Confusion matrix for label web:\n",
      "[[1846 1087]\n",
      " [ 562  488]]\n",
      "Confusion matrix for label internet:\n",
      "[[2144 1302]\n",
      " [ 319  218]]\n",
      "Confusion matrix for label culture:\n",
      "[[2181 1100]\n",
      " [ 420  282]]\n",
      "Confusion matrix for label design:\n",
      "[[1764 1140]\n",
      " [ 689  390]]\n",
      "Confusion matrix for label education:\n",
      "[[1926 1254]\n",
      " [ 497  306]]\n",
      "Confusion matrix for label language:\n",
      "[[1904 1596]\n",
      " [ 281  202]]\n",
      "Confusion matrix for label books:\n",
      "[[1958 1518]\n",
      " [ 301  206]]\n",
      "Confusion matrix for label writing:\n",
      "[[2051 1454]\n",
      " [ 267  211]]\n",
      "Confusion matrix for label computer:\n",
      "[[1907 1567]\n",
      " [ 277  232]]\n",
      "Confusion matrix for label english:\n",
      "[[2112 1516]\n",
      " [ 209  146]]\n",
      "Confusion matrix for label politics:\n",
      "[[2441 1150]\n",
      " [ 233  159]]\n",
      "Confusion matrix for label history:\n",
      "[[2059 1483]\n",
      " [ 238  203]]\n",
      "Confusion matrix for label philosophy:\n",
      "[[2585 1129]\n",
      " [ 144  125]]\n",
      "Confusion matrix for label science:\n",
      "[[2005 1477]\n",
      " [ 253  248]]\n",
      "Confusion matrix for label religion:\n",
      "[[2382 1394]\n",
      " [ 107  100]]\n",
      "Confusion matrix for label grammar:\n",
      "[[2081 1769]\n",
      " [  72   61]]\n"
     ]
    }
   ],
   "source": [
    "from imblearn import under_sampling, over_sampling\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "import pandas as pd\n",
    "# KMeans clustering a kind of clustering.\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "\n",
    "test_data,test_sentences = train_to_sentence_form(path+\"test-data.dat\")\n",
    "test_label = [i.strip() for i in open(path+\"test-label.dat\").readlines()]\n",
    "test_label = np.array(test_label)\n",
    "train_label = [i.strip() for i in open(path+\"train-label.dat\").readlines()]\n",
    "train_label = np.array(train_label)\n",
    "\n",
    "df = pd.read_csv(\"train_kmeans_.csv\") \n",
    "df_test = pd.read_csv(\"test_kmeans_.csv\")\n",
    "#train_label = pd.DataFrame(data = train_label)\n",
    "labels_models=[]\n",
    "for i in range (0,20 ):\n",
    "    tr=[]\n",
    "    for j in range (0,len(train_label)):\n",
    "        tr.append(int(train_label[j][2*i]))\n",
    "    labels_models.append(tr)\n",
    "    \n",
    "train_labels = pd.DataFrame(labels_models)\n",
    "train_labels = train_labels.transpose()\n",
    "#print(train_labels[:][2])\n",
    "labels__models=[]\n",
    "for i in range (0,20 ):\n",
    "    ts=[]\n",
    "    for j in range (0,len(test_label)):\n",
    "        ts.append(int(test_label[j][2*i]))\n",
    "    labels__models.append(ts)\n",
    "    \n",
    "test_labels = pd.DataFrame(labels__models)\n",
    "test_labels = test_labels.transpose()\n",
    "\n",
    "from sklearn import neighbors\n",
    "pred = pd.DataFrame()\n",
    "sm = SMOTE(sampling_strategy='minority', random_state=2)\n",
    "rm = RandomUnderSampler(random_state=42)\n",
    "df = df.drop(df.columns[0],axis=1)\n",
    "df_test = df_test.drop(df_test.columns[0],axis=1)\n",
    "dfinit = df.copy()\n",
    "print(df)\n",
    "orderlist = [2,7,4,0,8,6,5,12,10,9,17,11,15,14,3,13,16,1,18,19]\n",
    "for l in orderlist:\n",
    "    #if 4 * train_labels[train_labels[:][l] == 1].size < train_labels[train_labels[:][l] == 0].size:\n",
    "    df, train_labels_new = rm.fit_resample(dfinit,train_labels[:][l])\n",
    "    #else:\n",
    "    #df, train_labels_new = sm.fit_resample(dfinit, train_labels[:][l])\n",
    "    print(df.shape)\n",
    "    KNN = neighbors.KNeighborsClassifier(n_neighbors=3 ,weights='distance',metric='minkowski',p=1).fit(df, train_labels_new)\n",
    "    dfinit['Label'+str(l)] = train_labels[:][l]\n",
    "    df_test['Label'+str(l)] = KNN.predict(df_test) \n",
    "    pred['Label'+str(l)] = df_test['Label'+str(l)]\n",
    "    \n",
    "\n",
    "#clustnum = -1 smote\n",
    "#-2 randomundersampler\n",
    "'''sm = SMOTE(sampling_strategy='not majority', random_state=2)\n",
    "df, train_labels = sm.fit_resample(df, train_labels)\n",
    "\n",
    "\n",
    "KNN = neighbors.KNeighborsClassifier(n_neighbors=3 ,weights='distance',metric='minkowski',p=1).fit(df, train_labels)'''\n",
    "\n",
    "\n",
    "#pred = KNN.predict(df_test)\n",
    "#print(pred)\n",
    "predict=[]\n",
    "for p in range(3983):\n",
    "    #print(p)\n",
    "    result = []\n",
    "    for r in range(20):\n",
    "        x = orderlist.index(r)\n",
    "        result.append(pred.iloc[p,x])\n",
    "    predict.append(result)\n",
    "    \n",
    "multilabel_confusion_matrix(predict,path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
