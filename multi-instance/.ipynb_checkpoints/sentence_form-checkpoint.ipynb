{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "149925\n",
      "['rubi rail helper demo more info auto complet', 'see new helper action', 'null length substr locat', 'exec messag messag pleas edit remov follow word content', 'roll stone com news song previou next page', 'good vibrat beach boy', 'smell teen spirit nirvana', 'want hold hand beatl', 'hound dog elvi', 'god know beach boy', 'walk line johnni cash', 'heaven led zeppelin']\n",
      "149925\n",
      "965852\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "path = \"../Data/\"\n",
    "words = []\n",
    "\n",
    "\n",
    "def train_to_sentence_form(path):\n",
    "    # reads the file to a format of docs[doc[[sentence1],[sentence2]],...]\n",
    "    docs=[]\n",
    "    num_of_sentences = []\n",
    "    with open(path) as f:\n",
    "        line = f.readline()\n",
    "        while line:\n",
    "            line = line.rstrip('\\n').split(\" \")\n",
    "            #print(line)\n",
    "            num = line.pop(0)\n",
    "            #print(num)\n",
    "            number = int(num[1:-1])\n",
    "            num_of_sentences.append(number)\n",
    "            len_of_sentence = []\n",
    "\n",
    "            for i,k in enumerate(line):\n",
    "                if k.startswith('<'):\n",
    "                    k=k[1:-1]\n",
    "                    len_of_sentence.append(int(k))\n",
    "                    line.pop(i)\n",
    "            doc_sentence=[]       \n",
    "            sentence=[]\n",
    "            for j in len_of_sentence:\n",
    "                sentence = line[:j]\n",
    "                line=line[j:]\n",
    "                docs.append( sentence) \n",
    "            line = f.readline()\n",
    "    print(len(docs))\n",
    "    return docs,num_of_sentences     \n",
    "    #docs is a list of lists where each list is a different sentence\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "vocabs = open(path+\"vocabs.txt\").readlines()\n",
    "for vocab in vocabs:\n",
    "    word, _ = vocab.split(', ')\n",
    "    words.append(word)\n",
    "\n",
    "train_label = [i.strip() for i in open(path+\"train-label.dat\").readlines()]\n",
    "train_label = np.array(train_label)\n",
    "\n",
    "#path=\"../Data/\"\n",
    "docs,num_sentences = train_to_sentence_form(path+\"train-data.dat\")\n",
    "\n",
    "#train_data = convert_to_word(path + \"/train-data.dat\")\n",
    "data = []\n",
    "for i in docs:\n",
    "    final_L = ''\n",
    "    for l in i:\n",
    "        final_L = final_L + ' ' + words[int(l)]\n",
    "    data.append(final_L[1:])\n",
    "print(data[:12])\n",
    "print(len(data))       \n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(data)\n",
    "print(X_train_counts.size)\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multilabel_confusion_matrix(predict,path,clustnum):\n",
    "    test_label = [i.strip().split() for i in open(path + \"test-label.dat\").readlines()]\n",
    "\n",
    "    for i in range(len(test_label)):\n",
    "        item = test_label[i]\n",
    "        for j in range(len(item)):\n",
    "            item[j] = int(item[j])\n",
    "\n",
    "        test_label[i] = item\n",
    "\n",
    "    labels = []\n",
    "\n",
    "    for item in open(path + \"labels.txt\").readlines():\n",
    "        item = item.replace('\\n', '')\n",
    "        label_name, _ = item.split(', ')\n",
    "        labels.append(label_name)\n",
    "\n",
    "    y_true = np.array(test_label)\n",
    "    y_pred = np.array(predict)\n",
    "\n",
    "    conf_mat_dict = {}\n",
    "\n",
    "    for label_col in range(len(labels)):\n",
    "        y_true_label = y_true[:, label_col]\n",
    "        y_pred_label = y_pred[:, label_col]\n",
    "        conf_mat_dict[labels[label_col]] = confusion_matrix(y_pred=y_pred_label, y_true=y_true_label)\n",
    "    f = open(\"confmatrix\"+str(clustnum)+\".txt\", \"w\")\n",
    "    f.close()\n",
    "    for label, matrix in conf_mat_dict.items():\n",
    "        print(\"Confusion matrix for label {}:\".format(label))\n",
    "        f = open(\"confmatrix\"+str(clustnum)+\".txt\", \"a\")\n",
    "        print(matrix)\n",
    "        f.write(\"Confusion matrix for label {}:\".format(label))\n",
    "        np.savetxt(f,matrix)\n",
    "        f.close()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8251\n",
      "149925\n",
      "train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Peris\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73363\n",
      "fitting\n",
      "73363\n",
      "['1 0 1 1 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0'\n",
      " '0 0 1 0 1 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0'\n",
      " '0 0 1 0 1 1 0 0 0 0 1 0 0 0 0 1 0 0 0 0' ...\n",
      " '1 0 1 1 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0'\n",
      " '0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0'\n",
      " '0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0']\n",
      "Confusion matrix for label programming:\n",
      "[[2168  838]\n",
      " [ 422  555]]\n",
      "Confusion matrix for label style:\n",
      "[[3744   11]\n",
      " [ 227    1]]\n",
      "Confusion matrix for label reference:\n",
      "[[ 753 1672]\n",
      " [ 532 1026]]\n",
      "Confusion matrix for label java:\n",
      "[[2424 1187]\n",
      " [ 166  206]]\n",
      "Confusion matrix for label web:\n",
      "[[ 993 1940]\n",
      " [ 520  530]]\n",
      "Confusion matrix for label internet:\n",
      "[[ 163 3283]\n",
      " [  14  523]]\n",
      "Confusion matrix for label culture:\n",
      "[[3280    1]\n",
      " [ 700    2]]\n",
      "Confusion matrix for label design:\n",
      "[[2892   12]\n",
      " [1076    3]]\n",
      "Confusion matrix for label education:\n",
      "[[3144   36]\n",
      " [ 796    7]]\n",
      "Confusion matrix for label language:\n",
      "[[3491    9]\n",
      " [ 481    2]]\n",
      "Confusion matrix for label books:\n",
      "[[1112 2364]\n",
      " [ 170  337]]\n",
      "Confusion matrix for label writing:\n",
      "[[3134  371]\n",
      " [ 431   47]]\n",
      "Confusion matrix for label computer:\n",
      "[[1335 2139]\n",
      " [ 156  353]]\n",
      "Confusion matrix for label english:\n",
      "[[2947  681]\n",
      " [ 250  105]]\n",
      "Confusion matrix for label politics:\n",
      "[[3590    1]\n",
      " [ 390    2]]\n",
      "Confusion matrix for label history:\n",
      "[[2417 1125]\n",
      " [ 250  191]]\n",
      "Confusion matrix for label philosophy:\n",
      "[[3711    3]\n",
      " [ 269    0]]\n",
      "Confusion matrix for label science:\n",
      "[[3477    5]\n",
      " [ 499    2]]\n",
      "Confusion matrix for label religion:\n",
      "[[3775    1]\n",
      " [ 206    1]]\n",
      "Confusion matrix for label grammar:\n",
      "[[3850    0]\n",
      " [ 133    0]]\n",
      "149925\n",
      "train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Peris\\Anaconda3\\lib\\site-packages\\sklearn\\svm\\base.py:929: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  \"the number of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "73363\n",
      "fitting\n",
      "73363\n",
      "['0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 1 0 0'\n",
      " '0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 1 0 0'\n",
      " '0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 1 0 0' ...\n",
      " '0 0 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 1 0 0'\n",
      " '0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0'\n",
      " '0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0']\n",
      "Confusion matrix for label programming:\n",
      "[[2945   61]\n",
      " [ 928   49]]\n",
      "Confusion matrix for label style:\n",
      "[[3755    0]\n",
      " [ 228    0]]\n",
      "Confusion matrix for label reference:\n",
      "[[2349   76]\n",
      " [1503   55]]\n",
      "Confusion matrix for label java:\n",
      "[[3599   12]\n",
      " [ 372    0]]\n",
      "Confusion matrix for label web:\n",
      "[[2896   37]\n",
      " [1043    7]]\n",
      "Confusion matrix for label internet:\n",
      "[[3402   44]\n",
      " [ 532    5]]\n",
      "Confusion matrix for label culture:\n",
      "[[ 418 2863]\n",
      " [  71  631]]\n",
      "Confusion matrix for label design:\n",
      "[[2869   35]\n",
      " [1048   31]]\n",
      "Confusion matrix for label education:\n",
      "[[3143   37]\n",
      " [ 790   13]]\n",
      "Confusion matrix for label language:\n",
      "[[3421   79]\n",
      " [ 479    4]]\n",
      "Confusion matrix for label books:\n",
      "[[3473    3]\n",
      " [ 506    1]]\n",
      "Confusion matrix for label writing:\n",
      "[[ 456 3049]\n",
      " [  46  432]]\n",
      "Confusion matrix for label computer:\n",
      "[[3407   67]\n",
      " [ 502    7]]\n",
      "Confusion matrix for label english:\n",
      "[[3603   25]\n",
      " [ 354    1]]\n",
      "Confusion matrix for label politics:\n",
      "[[ 500 3091]\n",
      " [  36  356]]\n",
      "Confusion matrix for label history:\n",
      "[[3519   23]\n",
      " [ 439    2]]\n",
      "Confusion matrix for label philosophy:\n",
      "[[3708    6]\n",
      " [ 269    0]]\n",
      "Confusion matrix for label science:\n",
      "[[ 434 3048]\n",
      " [  86  415]]\n",
      "Confusion matrix for label religion:\n",
      "[[3770    6]\n",
      " [ 207    0]]\n",
      "Confusion matrix for label grammar:\n",
      "[[3782   68]\n",
      " [ 132    1]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "# KMeans clustering a kind of clustering.\n",
    "from sklearn.cluster import KMeans\n",
    "print(train_label.size)\n",
    "number_of_clusters_list = [3,5,10,20,50]\n",
    "for number_of_clusters in number_of_clusters_list:\n",
    "    km = KMeans(n_clusters=number_of_clusters)\n",
    "    # fit the matrix\n",
    "    km.fit(X_train_tfidf)\n",
    "    initform = np.zeros([train_label.size,number_of_clusters])\n",
    "    df = pd.DataFrame(initform,columns=[\"Cluster \"+ str(i) for i in range(number_of_clusters)])\n",
    "    print(km.labels_.size)\n",
    "    clust_labels = km.labels_\n",
    "    acc = 0\n",
    "    for i,val in enumerate(num_sentences):\n",
    "        for j in range(val):\n",
    "            df.iloc[i][clust_labels[acc]] += 1\n",
    "            acc+=1\n",
    "\n",
    "    df.head(20)\n",
    "\n",
    "\n",
    "    print(\"train\")\n",
    "    clf = LinearSVC().fit(df, train_label)\n",
    "\n",
    "    test_data,test_sentences = train_to_sentence_form(path+\"test-data.dat\")\n",
    "    test_label = [i.strip() for i in open(path+\"test-label.dat\").readlines()]\n",
    "    test_label = np.array(test_label)\n",
    "\n",
    "    data2 = []\n",
    "    for i in test_data:\n",
    "        final_L = ''\n",
    "        for l in i:\n",
    "            final_L = final_L + ' ' + words[int(l)]\n",
    "        data2.append(final_L[1:])\n",
    "\n",
    "    X_test_counts = count_vect.transform(data2)\n",
    "    X_test_tfidf = tfidf_transformer.transform(X_test_counts)\n",
    "    print(\"fitting\")\n",
    "    km.fit(X_test_tfidf)\n",
    "    print(km.labels_.size)\n",
    "\n",
    "    testform = np.zeros([test_label.size,number_of_clusters])\n",
    "    df_test = pd.DataFrame(testform,columns=[\"Cluster \"+ str(i) for i in range(number_of_clusters)])\n",
    "\n",
    "    clusttest_labels = km.labels_\n",
    "    acctest = 0\n",
    "    for i,val in enumerate(test_sentences):\n",
    "        for j in range(val):\n",
    "            df_test.iloc[i][clusttest_labels[acctest]] += 1\n",
    "            acctest+=1\n",
    "\n",
    "    df_test.head(20)\n",
    "\n",
    "    pred = clf.predict(df_test)\n",
    "    print(pred)\n",
    "    \n",
    "    predict=[]\n",
    "    for p in pred:\n",
    "        result = p.split()\n",
    "        for r in range(len(result)):\n",
    "            result[r] = int(result[r])\n",
    "        predict.append(result)\n",
    "    \n",
    "    multilabel_confusion_matrix(predict,path,number_of_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
